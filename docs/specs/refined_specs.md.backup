# Priority 3: The Semantic Cortex Upgrade (v3.0 - The 99% Spec)

**Vision:** A Polymorphic Cognitive Engine where Graph (Logic) and Vector (Vibe) memories are physically distinct but logically unified via a shared Entity Index.

---

## Phase 1: The Foundation (Unified Data Model)

**Objective:** Establish the Schema.

### 1.1. Database Schema (`semantic_triples`)

| Column | Type | Purpose | Indexing |
|:---|:---|:---|:---|
| `id` | UUID | Primary Key | PK |
| `subject_id` | String | The "Node" A (Canonical URI) | Composite Index (SPO) |
| `predicate` | String | The "Edge" Label | Composite Index (SPO) |
| `object_id` | String | The "Node" B (Canonical URI) | Composite Index (SPO, OSP) |
| `graph_id` | String | Tenant ID (e.g., "project:X") | Partial Index |
| `context` | Map | Metadata (provenance, confidence) | GIN Index |
| `expires_at`| DateTime | TTL for temporary facts | Partial Index |

---

## Phase 2: The Senses (Ingestion & Resolution)

**Objective:** Convert raw text into Canonical Triples.

### 2.1. The Entity Resolver (`Mimo.SemanticStore.Resolver`)

**The Problem:** User says "The DB", Graph knows "db:postgres".
**The Solution:** Vector-backed Entity Linking.

**Logic:**
1.  **Search:** Vector search `engrams` table for type `entity_anchor` matching "The DB".
2.  **Match:**
    *   If `score > 0.85`: Return canonical ID (`db:postgres`).
    *   If `score < 0.85`: Create NEW Entity.
        1.  Generate ID: `entity:the_db`.
        2.  Store Semantic Node.
        3.  Store Vector Anchor: `content="The DB"`, `type="entity_anchor"`, `ref="entity:the_db"`.

### 2.2. The Text Adapter (`Mimo.SemanticStore.Sources.Text`)

**Logic:**
1.  **Extract:** LLM returns `{"subject": "The DB", "predicate": "is_slow"}`.
2.  **Resolve:** Call `Resolver.resolve("The DB")` -> `db:postgres`.
3.  **Structure:** Return `%Triple{subject_id: "db:postgres", ...}`.

---

## Phase 3: The Dreamer (Async Inference)

**Objective:** Background reasoning.

### 3.1. The Dreamer GenServer (`Mimo.SemanticStore.Dreamer`)

**Guard Rail:** SQLite Concurrency Control.
- [ ] **Transaction Mode:** logic runs inside `Repo.transaction` with `mode: :immediate` to handle SQLite locking gracefully.
- [ ] **Debounce:** Only run inference pass every 500ms to allow high-throughput writes to settle.

---

## Phase 4: The Brain (Router Integration)

**Objective:** Intelligent, Deterministic Routing.

### 4.1. The Intent Classifier (`Mimo.Brain.Classifier`)

**The Problem:** "How do I fix this?" (Ambiguous) vs "What depends on User?" (Graph).
**The Solution:** Keyword Fast-Path + LLM Slow-Path.

**Logic:**
1.  **Fast Path (Regex):**
    *   If query matches `~r/(depend|relation|hierarchy|parent|child|cause)/i` -> **GRAPH**.
    *   If query matches `~r/(feel|vibe|tone|style|story)/i` -> **VECTOR**.
2.  **Slow Path (LLM):**
    *   If no regex match, call LLM: `Classify user query: "${query}". Output strictly: LOGIC or NARRATIVE`.
    *   **LOGIC** -> Graph.
    *   **NARRATIVE** -> Vector.

---

## Phase 5: The Mouth (Agent Tools)

**Objective:** Explicit access.

### 5.1. Semantic Toolset (`Mimo.Tools.Semantic`)

- `consult_graph(query)`: Calls `Resolver` -> `Query.transitive_closure`.
- `teach_mimo(fact)`: Calls `Ingestor` (which calls `Resolver` -> `Repo.insert` -> `Dreamer`).

---

## Phase 6: Active Inference (Observer)

**Objective:** Proactive context.

### 6.1. The Observer (`Mimo.SemanticStore.Observer`)

**Guard Rail:** Context Flooding Prevention.
- [ ] **Token Budget:** The Observer checks the current conversation token count. If > 80% full, it suppresses proactive context.
